{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2b. Machine Learning using tf.estimator </h1>\n",
    "\n",
    "In this notebook, we will create a machine learning model using tf.estimator and evaluate its performance.  The dataset is rather small (7700 samples), so we can do it all in-memory.  We will also simply pass the raw data in as-is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.10.0\n",
      "google-cloud-bigquery Version: 1.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# import datalab.bigquery as bq\n",
    "from google.cloud import bigquery\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "print('Tensorflow Version:',tf.__version__)\n",
    "print('google-cloud-bigquery Version:',bigquery.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data created in the previous chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In CSV, label is the first column, after the features, followed by the key\n",
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "FEATURES = CSV_COLUMNS[1:len(CSV_COLUMNS) - 1]\n",
    "LABEL = CSV_COLUMNS[0]\n",
    "\n",
    "df_train = pd.read_csv('./taxi-train.csv', header = None, names = CSV_COLUMNS)\n",
    "df_valid = pd.read_csv('./taxi-valid.csv', header = None, names = CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-73.987625</td>\n",
       "      <td>40.750617</td>\n",
       "      <td>-73.971163</td>\n",
       "      <td>40.785180</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.963620</td>\n",
       "      <td>40.774363</td>\n",
       "      <td>-73.953485</td>\n",
       "      <td>40.772665</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.989649</td>\n",
       "      <td>40.756633</td>\n",
       "      <td>-73.985597</td>\n",
       "      <td>40.765662</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-73.993950</td>\n",
       "      <td>40.727524</td>\n",
       "      <td>-74.006584</td>\n",
       "      <td>40.744240</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>-73.950223</td>\n",
       "      <td>40.668960</td>\n",
       "      <td>-73.948112</td>\n",
       "      <td>40.668872</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount  pickuplon  pickuplat  dropofflon  dropofflat  passengers  key\n",
       "0         12.0 -73.987625  40.750617  -73.971163   40.785180           1    0\n",
       "1          4.5 -73.963620  40.774363  -73.953485   40.772665           1    1\n",
       "2          4.5 -73.989649  40.756633  -73.985597   40.765662           1    2\n",
       "3         10.0 -73.993950  40.727524  -74.006584   40.744240           1    3\n",
       "4          2.5 -73.950223  40.668960  -73.948112   40.668872           6    4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fare_amount',\n",
       " 'pickuplon',\n",
       " 'pickuplat',\n",
       " 'dropofflon',\n",
       " 'dropofflat',\n",
       " 'passengers',\n",
       " 'key']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickuplon', 'pickuplat', 'dropofflon', 'dropofflat', 'passengers']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Input function to read from Pandas Dataframe </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(df, num_epochs):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "            x = df,\n",
    "            y = df[LABEL],\n",
    "            batch_size = 128,\n",
    "            num_epochs = num_epochs,\n",
    "            shuffle = True,\n",
    "            queue_capacity = 1000,\n",
    "            num_threads = 1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.estimator.inputs.pandas_io.pandas_input_fn.<locals>.input_fn()>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_input_fn(df_train, num_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature columns for estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_cols():\n",
    "    input_columns = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "    return input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='pickuplon', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='pickuplat', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='dropofflon', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='dropofflat', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='passengers', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_feature_cols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Regression with tf.Estimator framework </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'taxi_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f66fa007cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 29004.79, step = 1\n",
      "INFO:tensorflow:global_step/sec: 584.85\n",
      "INFO:tensorflow:loss = 8876.701, step = 101 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.916\n",
      "INFO:tensorflow:loss = 6913.442, step = 201 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 598.46\n",
      "INFO:tensorflow:loss = 9650.768, step = 301 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.091\n",
      "INFO:tensorflow:loss = 7601.5195, step = 401 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.646\n",
      "INFO:tensorflow:loss = 5109.2563, step = 501 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.334\n",
      "INFO:tensorflow:loss = 8612.174, step = 601 (0.157 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 608 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 68.65168.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f66fa007b00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "# tf.logging.set_verbosity(tf.logging.WARN)\n",
    "\n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # Delete an entire directory tree, and thus start fresh each time\n",
    "# 也就是说'taxi_trained' directory 每次都会被删掉\n",
    "\n",
    "model = tf.estimator.LinearRegressor(\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "\n",
    "model.train(input_fn = make_input_fn(df_train, num_epochs = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the validation data (we should defer using the test data to after we have selected a final model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-11:11:56\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-608\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-11:11:57\n",
      "INFO:tensorflow:Saving dict for global step 608: average_loss = 109.352234, global_step = 608, label/mean = 11.666427, loss = 13005.1045, prediction/mean = 10.937778\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 608: taxi_trained/model.ckpt-608\n",
      "RMSE on validation dataset = 10.457161903381348\n"
     ]
    }
   ],
   "source": [
    "def print_rmse(model, name, df):\n",
    "    metrics = model.evaluate(input_fn = make_input_fn(df, 1))\n",
    "    print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))\n",
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nowhere near our benchmark (RMSE of $6 or so on this data), but it serves to demonstrate what TensorFlow code looks like.  Let's use this model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'taxi_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f66f9124780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-608\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Predictions:\n",
      " [10.902043, 10.902542, 10.887774, 10.901521, 11.149463]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "# Read saved model and use it for prediction\n",
    "model = tf.estimator.LinearRegressor(\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "preds_iter = model.predict(input_fn = make_input_fn(df_valid, 1))\n",
    "print('\\nPredictions:\\n',[pred['predictions'][0] for pred in list(itertools.islice(preds_iter, 5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explains why the RMSE was so high -- the model essentially predicts the same amount for every trip.  Would a more complex model help? Let's try using a deep neural network.  The code to do this is quite straightforward as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deep Neural Network regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'taxi_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f66f9d63780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 94694.85, step = 1\n",
      "INFO:tensorflow:global_step/sec: 556.722\n",
      "INFO:tensorflow:loss = 36416.484, step = 101 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.926\n",
      "INFO:tensorflow:loss = 31398.533, step = 201 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.938\n",
      "INFO:tensorflow:loss = 23765.355, step = 301 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 594.987\n",
      "INFO:tensorflow:loss = 17538.271, step = 401 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.508\n",
      "INFO:tensorflow:loss = 23452.82, step = 501 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.952\n",
      "INFO:tensorflow:loss = 13707.97, step = 601 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.601\n",
      "INFO:tensorflow:loss = 21256.21, step = 701 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.162\n",
      "INFO:tensorflow:loss = 20880.541, step = 801 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.848\n",
      "INFO:tensorflow:loss = 20109.18, step = 901 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.598\n",
      "INFO:tensorflow:loss = 24837.02, step = 1001 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.805\n",
      "INFO:tensorflow:loss = 17588.096, step = 1101 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.406\n",
      "INFO:tensorflow:loss = 17720.525, step = 1201 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.335\n",
      "INFO:tensorflow:loss = 19137.281, step = 1301 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.23\n",
      "INFO:tensorflow:loss = 15534.517, step = 1401 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.476\n",
      "INFO:tensorflow:loss = 16219.505, step = 1501 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.729\n",
      "INFO:tensorflow:loss = 16514.988, step = 1601 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.708\n",
      "INFO:tensorflow:loss = 20120.168, step = 1701 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.712\n",
      "INFO:tensorflow:loss = 17869.348, step = 1801 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.996\n",
      "INFO:tensorflow:loss = 17612.473, step = 1901 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.582\n",
      "INFO:tensorflow:loss = 16272.609, step = 2001 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.429\n",
      "INFO:tensorflow:loss = 22413.695, step = 2101 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.916\n",
      "INFO:tensorflow:loss = 14501.878, step = 2201 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.758\n",
      "INFO:tensorflow:loss = 19355.88, step = 2301 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 677.719\n",
      "INFO:tensorflow:loss = 9161.787, step = 2401 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 695.215\n",
      "INFO:tensorflow:loss = 18740.523, step = 2501 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.313\n",
      "INFO:tensorflow:loss = 11114.942, step = 2601 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 594.4\n",
      "INFO:tensorflow:loss = 16514.035, step = 2701 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.461\n",
      "INFO:tensorflow:loss = 15100.089, step = 2801 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.344\n",
      "INFO:tensorflow:loss = 10806.586, step = 2901 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.289\n",
      "INFO:tensorflow:loss = 14950.815, step = 3001 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.525\n",
      "INFO:tensorflow:loss = 19240.379, step = 3101 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.494\n",
      "INFO:tensorflow:loss = 16544.531, step = 3201 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.148\n",
      "INFO:tensorflow:loss = 15286.6045, step = 3301 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.738\n",
      "INFO:tensorflow:loss = 18924.25, step = 3401 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.689\n",
      "INFO:tensorflow:loss = 21346.52, step = 3501 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.587\n",
      "INFO:tensorflow:loss = 17409.076, step = 3601 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.298\n",
      "INFO:tensorflow:loss = 14414.094, step = 3701 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.746\n",
      "INFO:tensorflow:loss = 10840.441, step = 3801 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.374\n",
      "INFO:tensorflow:loss = 16909.947, step = 3901 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.809\n",
      "INFO:tensorflow:loss = 10213.969, step = 4001 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.038\n",
      "INFO:tensorflow:loss = 21769.125, step = 4101 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.637\n",
      "INFO:tensorflow:loss = 14975.512, step = 4201 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.654\n",
      "INFO:tensorflow:loss = 13497.65, step = 4301 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.959\n",
      "INFO:tensorflow:loss = 18231.016, step = 4401 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.408\n",
      "INFO:tensorflow:loss = 8820.609, step = 4501 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 695.104\n",
      "INFO:tensorflow:loss = 5535.62, step = 4601 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.297\n",
      "INFO:tensorflow:loss = 14366.936, step = 4701 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.305\n",
      "INFO:tensorflow:loss = 14229.309, step = 4801 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.554\n",
      "INFO:tensorflow:loss = 11101.871, step = 4901 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.001\n",
      "INFO:tensorflow:loss = 23586.543, step = 5001 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.368\n",
      "INFO:tensorflow:loss = 16803.684, step = 5101 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.725\n",
      "INFO:tensorflow:loss = 16571.133, step = 5201 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.017\n",
      "INFO:tensorflow:loss = 21679.902, step = 5301 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.28\n",
      "INFO:tensorflow:loss = 14966.061, step = 5401 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.367\n",
      "INFO:tensorflow:loss = 18054.281, step = 5501 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 688.938\n",
      "INFO:tensorflow:loss = 15444.006, step = 5601 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.522\n",
      "INFO:tensorflow:loss = 11816.27, step = 5701 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.064\n",
      "INFO:tensorflow:loss = 15060.595, step = 5801 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.413\n",
      "INFO:tensorflow:loss = 10243.837, step = 5901 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.929\n",
      "INFO:tensorflow:loss = 16228.236, step = 6001 (0.149 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6071 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7641.506.\n",
      "--------------------------------------\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-11:12:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-6071\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-11:12:07\n",
      "INFO:tensorflow:Saving dict for global step 6071: average_loss = 103.859955, global_step = 6071, label/mean = 11.091295, loss = 13229.375, prediction/mean = 6.455007\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6071: taxi_trained/model.ckpt-6071\n",
      "RMSE on train dataset = 10.191170692443848\n",
      "--------------------------------------\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-11:12:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-6071\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-11:12:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 6071: average_loss = 135.93861, global_step = 6071, label/mean = 11.666427, loss = 16166.985, prediction/mean = 6.4550023\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6071: taxi_trained/model.ckpt-6071\n",
      "RMSE on validation dataset = 11.659271240234375\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "model = tf.estimator.DNNRegressor(hidden_units = [32, 8, 2],\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "model.train(input_fn = make_input_fn(df_train, num_epochs = 100));\n",
    "\n",
    "print('--------------------------------------')\n",
    "print_rmse(model, 'train', df_train)\n",
    "print('--------------------------------------')\n",
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not beating our benchmark with either model ... what's up?  Well, we may be using TensorFlow for Machine Learning, but we are not yet using it well.  That's what the rest of this course is about!\n",
    "\n",
    "But, for the record, let's say we had to choose between the two models. We'd choose the one with the lower validation error. Finally, we'd measure the RMSE on the test data with this chosen model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Benchmark dataset </h2>\n",
    "\n",
    "Let's do this on the benchmark dataset.\n",
    "\n",
    "- using legacy SQL: https://googlecloudplatform.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.QueryJobConfig.html#google.cloud.bigquery.job.QueryJobConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# use legacy sql\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "job_config.use_legacy_sql = True\n",
    "\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "\n",
    "def create_query(phase, EVERY_N):\n",
    "    \"\"\"\n",
    "    phase: 1 = train 2 = valid\n",
    "    \"\"\"\n",
    "    base_query = \"\"\"\n",
    "    SELECT\n",
    "      (tolls_amount + fare_amount) AS fare_amount,\n",
    "      CONCAT(STRING(pickup_datetime), STRING(pickup_longitude), STRING(pickup_latitude), STRING(dropoff_latitude), STRING(dropoff_longitude)) AS key,\n",
    "      DAYOFWEEK(pickup_datetime)*1.0 AS dayofweek,\n",
    "      HOUR(pickup_datetime)*1.0 AS hourofday,\n",
    "      pickup_longitude AS pickuplon,\n",
    "      pickup_latitude AS pickuplat,\n",
    "      dropoff_longitude AS dropofflon,\n",
    "      dropoff_latitude AS dropofflat,\n",
    "      passenger_count*1.0 AS passengers\n",
    "    FROM\n",
    "      [nyc-tlc:yellow.trips]\n",
    "    WHERE\n",
    "      trip_distance > 0\n",
    "      AND fare_amount >= 2.5\n",
    "      AND pickup_longitude > -78\n",
    "      AND pickup_longitude < -70\n",
    "      AND dropoff_longitude > -78\n",
    "      AND dropoff_longitude < -70\n",
    "      AND pickup_latitude > 37\n",
    "      AND pickup_latitude < 45\n",
    "      AND dropoff_latitude > 37\n",
    "      AND dropoff_latitude < 45\n",
    "      AND passenger_count > 0\n",
    "  \"\"\"\n",
    "\n",
    "    if EVERY_N == None:\n",
    "        if phase < 2:\n",
    "          # Training\n",
    "          query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 < 2\".format(base_query)\n",
    "        else:\n",
    "          # Validation\n",
    "          query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 == {1}\".format(base_query, phase)\n",
    "    else:\n",
    "        query = \"{0} AND ABS(HASH(pickup_datetime)) % {1} == {2}\".format(base_query, EVERY_N, phase)\n",
    "\n",
    "    return query\n",
    "\n",
    "query = create_query(2, 100000)\n",
    "row=client.query(query, job_config=job_config)\n",
    "df=row.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x7f66f91d5e48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>key</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1</td>\n",
       "      <td>2011-03-06 21:01:00.000000-74.003440.749340.77...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-74.003402</td>\n",
       "      <td>40.749272</td>\n",
       "      <td>-73.963575</td>\n",
       "      <td>40.774550</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.7</td>\n",
       "      <td>2012-04-27 18:37:09.000000-73.991740.764940.79...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-73.991711</td>\n",
       "      <td>40.764878</td>\n",
       "      <td>-73.966193</td>\n",
       "      <td>40.795124</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.9</td>\n",
       "      <td>2009-07-04 13:00:57.000000-74.001640.730840.75...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-74.001624</td>\n",
       "      <td>40.730758</td>\n",
       "      <td>-73.992518</td>\n",
       "      <td>40.753710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>2012-11-03 17:11:00.000000-74.007540.741940.76...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-74.007512</td>\n",
       "      <td>40.741902</td>\n",
       "      <td>-73.989882</td>\n",
       "      <td>40.763757</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2012-11-03 17:11:00.000000-73.994540.726140.75...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-73.994495</td>\n",
       "      <td>40.726140</td>\n",
       "      <td>-73.969757</td>\n",
       "      <td>40.753692</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount                                                key  dayofweek  \\\n",
       "0         10.1  2011-03-06 21:01:00.000000-74.003440.749340.77...        1.0   \n",
       "1          9.7  2012-04-27 18:37:09.000000-73.991740.764940.79...        6.0   \n",
       "2          6.9  2009-07-04 13:00:57.000000-74.001640.730840.75...        7.0   \n",
       "3          8.5  2012-11-03 17:11:00.000000-74.007540.741940.76...        7.0   \n",
       "4         10.0  2012-11-03 17:11:00.000000-73.994540.726140.75...        7.0   \n",
       "\n",
       "   hourofday  pickuplon  pickuplat  dropofflon  dropofflat  passengers  \n",
       "0       21.0 -74.003402  40.749272  -73.963575   40.774550         1.0  \n",
       "1       18.0 -73.991711  40.764878  -73.966193   40.795124         1.0  \n",
       "2       13.0 -74.001624  40.730758  -73.992518   40.753710         1.0  \n",
       "3       17.0 -74.007512  40.741902  -73.989882   40.763757         5.0  \n",
       "4       17.0 -73.994495  40.726140  -73.969757   40.753692         1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-11:12:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-6071\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-11:12:11\n",
      "INFO:tensorflow:Saving dict for global step 6071: average_loss = 112.33982, global_step = 6071, label/mean = 11.333682, loss = 14278.68, prediction/mean = 6.4550095\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6071: taxi_trained/model.ckpt-6071\n",
      "RMSE on benchmark dataset = 10.599047660827637\n"
     ]
    }
   ],
   "source": [
    "print_rmse(model, 'benchmark', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE on benchmark dataset is <b>9.41</b> (your results will vary because of random seeds).\n",
    "\n",
    "This is not only way more than our original benchmark of 6.00, but it doesn't even beat our distance-based rule's RMSE of 8.02.\n",
    "\n",
    "Fear not -- you have learned how to write a TensorFlow model, but not to do all the things that you will have to do to your ML model performant. We will do this in the next chapters. In this chapter though, we will get our TensorFlow model ready for these improvements.\n",
    "\n",
    "In a software sense, the rest of the labs in this chapter will be about refactoring the code so that we can improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
